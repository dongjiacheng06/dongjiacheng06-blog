# DSG-World: Learning a 3D Gaussian World Model from Dual State Videos

Status: Done
DOI：: https://arxiv.org/pdf/2506.05217

## 背景：

1. 从有限稀疏的观测中重建模型是一个挑战
2. 目前大部分模型生成依赖隐式生成模型
    1. Hard to train
    2.  black box
3. 基于单个状态的显式三维方法（如三维高斯溅射）在物体移动后，会因为遮挡而留下空洞，需要依赖分割、修复等多个处理阶段。 这个过程不仅复杂，而且2D分割的不准确性会传递到3D空间，导致伪影和模糊，影响模拟的保真度。
4. 密集观测的依赖

---

## 方法

1. 从两个状态的场景中构建两个独立的三维高斯场
2. Bidirectional Alignment   
3. Pseudo-state Guided Alignment
4. Collaborative Co-Pruning

---

## 目的

~~训练一个模型，使模型能正确移动物体~~

从有限的、稀疏的真实观测中，构建一个完整、可编辑的三维世界模型（包括物体遮挡的部分）

我感觉有点像3DGS：A与B的融合，通过A与B两个数据，产生一个完整的背景与前景（前景的标签是本来通过掩码获得的？）

输入是A与B与他们的图像掩码（如何获得？）

---

## Q&A

### Q：

**图像掩码是三维重构的每一张图片都要用一个框框起来吗？**

### A：

- **输入内容**：输入确实是状态A和状态B的两组图像集，以及它们对应的分割掩码 。
- **什么是图像掩码**：图像掩码**不是用一个“框框起来”**（那个叫“边界框”，Bounding Box）。“分割掩码 (Segmentation Mask)”要精确得多，它是一个与原始图像大小完全相同的图层，用不同的颜色**像素级地**标出了每个物体轮廓的精确范围。