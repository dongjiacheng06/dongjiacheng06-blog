# GaussianCut: Interactive Segmentation via Graph Cut for 3D Gaussian Splatting

Status: To read
DOI：: https://arxiv.org/pdf/2411.07555

## 概括

---

GaussianCut 是一种新方法，可以让你在由3D高斯点构成的3D场景里，通过互动来选中并分割出你想要的物体。你只需要在一张2D图片上随便点几下、画几笔或者输入文字，它就能自动把整个3D场景里的高斯点分成“前景”（你选中的物体）和“背景”。

它的核心原理是把所有3D高斯点看作一个关系图（Graph），然后用经典的“图割”（Graph Cut）算法，来高效地把物体从场景里“切割”出来。这个方法最大的好处是，它作用于已经训练好的3D场景，不需要任何额外的训练。

![image.png](GaussianCut%20Interactive%20Segmentation%20via%20Graph%20Cut%2023998aeef83680e1bdd1de5db66b4764/image.png)

---

## 背景：

---

在编辑3D场景时，能够准确地选中并分离出某个物体是非常基础且重要的一步。3D高斯技术（3DGS）虽然能实时渲染出非常逼真的图像，但在这种表示方法里分割物体却很有挑战性。

以前的方法通常需要为大量的训练图片手动绘制精确的2D蒙版，或者需要给模型增加一个专门负责分割的组件并重新训练，这既费时又消耗计算资源。GaussianCut解决了这个问题，它提供了一种交互式的、免训练的方法，直接对已有的3D场景进行操作。

---

## Related work（3D分割）

---

1.   Training 3D segmentation with 2D masks/features（借助2D已有的工作）
    1. 使用2Dmask，如SAM，将不同视图的2D蒙版在3D空间聚合以实现分割
    2. 
2. Segmentation in 3D Gaussian Splatting
    1. 把3D高斯打上标签然后使用2D图像特征来监督（不懂）
3.  Graph cut for 3D segmentation

---

## 方法

---

1.  **将用户输入映射到高斯（不透明度x透射率加权）**

![image.png](GaussianCut%20Interactive%20Segmentation%20via%20Graph%20Cut%2023998aeef83680e1bdd1de5db66b4764/image%201.png)

1. **构建高斯图网络**：将场景中所有的3D高斯点组织成一个图（Graph），点与点之间通过边连接。
2. **通过图割算法优化分割**：在图上定义一个能量函数，然后用图割算法找到最优分割方案，将前景和背景精确分离开。

能量函数：

![image.png](GaussianCut%20Interactive%20Segmentation%20via%20Graph%20Cut%2023998aeef83680e1bdd1de5db66b4764/image%202.png)

---

## 实验

---

---

## 讨论与局限

---

**优点:** GaussianCut提供了一种非常直观、方便的交互方式来分割3D场景，而且不需要修改模型或重新训练。它巧妙地将强大的图割优化算法应用到了这个新领域。

---

## Q&A

---

### Q:把3D高斯打上标签然后使用2D图像特征来监督（不懂）

### A:

- **准备“老师的答案” (提取2D特征)**：首先，研究人员会用一个非常强大的、预训练好的2D图像模型（比如文中提到的DINO 或其他视频分割模型 ）去处理所有的2D训练照片。这个2D模型会为每张照片的每个像素生成一个“特征向量”，这个向量包含了丰富的语义信息（比如，这个像素是属于“卡车”、“天空”还是“地面”）。这个由2D模型生成的特征图，就成了“标准答案”或“老师的参考书”。
- **3D模型“交作业” (渲染3D特征)**：在训练3DGS模型时，每个3D高斯体除了有颜色、位置等基本属性外，还有一个**可学习的额外特征向量** 。在训练的每一步，3DGS模型会把这些带有“特征”的高斯体渲染（投影）成一张2D的“特征图”。这就好比3D模型根据自己的理解，画出了一张带有语义信息的画，交上来当作业。
- **“老师批改作业” (计算差异)**：现在，对于同一个像素位置，我们有了两份“作业”：一份是“老师的标准答案”（来自强大的2D模型），另一份是“3D学生交的作业”（3DGS渲染出的特征图）。系统会比较这两个特征向量的差异。
- **“学生订正错误” (反向传播优化)**：如果差异很大，系统就会通过算法（反向传播）去调整3D高斯体上的那个**额外特征**，让它下次渲染出来的结果能更接近“老师的标准答案”。

---

### Q:

**3DGS模型会把这些带有“特征”的高斯体渲染（投影）成一张2D的“特征图”?**

### A:

简单来说，**这一步就是用3DGS的渲染管线，把每个高斯体携带的“特征向量”而不是“颜色”，绘制成一张2D图片**。

让我们把它和普通的3DGS渲染做个对比，您就明白了：

**1. 普通的3DGS渲染（生成彩色图）**

- **输入**：每个3D高斯体都带有一个**颜色**属性（通常由球谐函数表示）。
- **过程**：
    1. **投影**：从某个摄像机视角，把所有三维空间中的高斯体投影到二维屏幕上。
    2. **混合(Alpha Blending)**：对于屏幕上的每一个像素，可能会有多个半透明的、带有**颜色**的高斯体覆盖它。渲染器会根据这些高斯体的前后顺序和透明度，将它们的**颜色**混合起来，得到这个像素最终的颜色值（一个RGB三维向量）。
- **输出**：一张我们肉眼可见的彩色2D图像。

---

**2. 渲染“特征图”**

- **输入**：每个3D高斯体除了颜色，还带有一个额外的、可学习的**特征向量**（比如一个32维的向量）。
- **过程**：
    1. **投影**：和普通渲染完全一样，把所有高斯体投影到二维屏幕上。
    2. **混合(Alpha Blending)**：对于屏幕上的每一个像素，渲染器做同样的事情，但这次混合的不是**颜色**，而是每个高斯体携带的**特征向量**。它会根据前后顺序和透明度，对覆盖该像素的所有高斯体的**特征向量**进行加权平均。
- **输出**：一张肉眼看不见的“特征图”。这张图的每个像素值不再是RGB颜色，而是一个新的、混合后的**特征向量**（比如一个32维的向量）。

这个输出的“2D特征图”就代表了3D模型在当前视角下对场景语义的“理解”。因为它是在2D平面上的，所以可以直接与前面提到的、由强大2D模型生成的“老师的答案”（也是一张2D特征图）进行逐像素的比较，从而计算差异并指导3D模型进行学习和优化。

---