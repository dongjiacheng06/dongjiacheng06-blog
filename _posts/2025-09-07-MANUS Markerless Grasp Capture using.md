---
title: "MANUS: Markerless Grasp Capture using Articulated 3D Gaussians"
date: 2025-09-07 17:57:00 +0800
categories: [3D Vision, Research]
tags: [3DGS, HANDS, Multi-View, 手部重建, 数据集，手部模型]
math: true
DOI：: https://arxiv.org/abs/2312.02137
开源代码: https://github.com/manuel-d-cruz/MANUS
mermaid: true
image:
  path: /assets/images/MANUS.png
  alt: MANUS方法的流程图
---

## 1. 核心

---

- 在不戴手套/不贴标记（markerless）的条件下，从多视角 RGB 视频中**高保真地捕捉手—物体抓握**，核心在于**精确估计接触（contact）**区域与时序。
- **痛点**：以往用**骨架、网格或参数模型（如 MANO）表示手，形状表达维度低、与像素对齐不足，导致接触估计不准**；隐式场（SDF/NeRF 类）虽拟合好但**采样代价高、接触推断昂贵**。
- **核心洞见**：用**3D Gaussian Splatting（3DGS）构建可动手部模型**与**静态物体模型**，都由**显式高斯元**（位置、取向、尺度、SH颜色）组成——显式几何便于**快速、直接**算手与物体的**瞬时/累计接触**；再配合**超多视角**可显著缓解遮挡，提升像素级对齐。

---

## 2. 问题/背景：

---

以往用**骨架、网格或参数模型（如 MANO）表示手，形状表达维度低、与像素对齐不足，导致接触估计不准**；隐式场（SDF/NeRF 类）虽拟合好但**采样代价高、接触推断昂贵**。

---

## 3. 方法

---

### 3.1 Pipeline

- **MANUS-Hand（手部）**：基于 3DGS 的**模板无关**、**可驱动**手模型；
- **物体 3DGS 表示**：静态高斯集合；
- **抓握与接触估计**：将手与物体高斯在同一坐标系**拼接渲染**，并据**3D 最近邻距离阈值**得到**瞬时/累计接触图**。

### 3.2 MANUS-Hand：关节驱动的高斯手

- 21 bones、26 DOF 的骨架；在**规范空间**（canonical）学习一组手的 3D 高斯：均值 μ、协方差 Σ、透明度 α、SH 系数 φ；协方差参数化为 **Σ = R S Sᵀ Rᵀ**。
- 通过**正向运动学（FK）+ 线性蒙皮（LBS）将规范空间的高斯映射到姿态空间**：
    - 位置：μ_p = T_g μ；
    - 协方差：Σ_p = R_g Σ R_gᵀ；
    - 颜色：将视线方向从姿态空间回到规范空间，用 φ 查询。
- **关键：蒙皮权重的稳健初始化**。不是把 MANO 权重直接“近邻”分给高斯（会漂移错绑），而是在规范空间构建**体素网格**存放权重，再对任意高斯做**三线性插值**得到 W，避免训练中高斯漂移造成的错配。

---

### 输入与前置

- **多视角 RGB 视频 + 标定**：50+ 台相机，120 FPS，1280×720，COLMAP 求内外参；需要**几十个视角**来缓解自遮挡、保证像素级对齐。
- **分割与关键点**：SAM 分割出手/物体；Instant-NGP 做多视图一致性掩膜。AlphaPose → 多视角三角化 → 逆运动学（加关节限幅）→ 1C Filter 做时序平滑，得到**骨架序列**。

### 阶段A：学一个可动的 3DGS 手（MANUS-Hand）

1. **表示**：在**规范空间**学习手的 3D 高斯（位置、协方差、透明度、SH 颜色），这是一个可微光栅化的 3DGS 模型。核心选择 3DGS 是为了显式位置/朝向、优化与推理都更快。
2. **从规范到姿态**：利用骨架做 FK + LBS，把规范空间高斯变到**当前姿态**（位置与协方差随骨骼变换）；渲染得到对应视图。
3. **训练目标**：图像重建（L1、SSIM、LPIPS）+ **各向同性正则**（抑制“针状高斯”，利于后续接触渲染稳定），最终损失 $L_h=\alpha L_1+\beta L_{SSIM}+\gamma L_{perc}+\delta L_{iso}$。

### 阶段B：学一个静态 3DGS 物体

- 和手类似，但**不带骨架**；训练时把投影到掩膜外的“漂浮高斯”剔除，保证几何一致与精度。

### 阶段C：抓握重建（合成“手+物体”场景）

1. **姿态驱动手**：用阶段A学到的 MANUS-Hand，喂入上一节得到的**每帧骨架**，得到该帧手部的“姿态高斯”。
2. **拼接并渲染**：把**物体高斯集合 G_o** 与 **手高斯集合 G_h** **直接级联**成 $G_f=\{G_o,G_h\}$，交给 3DGS 光栅器即可渲该帧抓握图像（显式高斯支持这种“拼即用”，隐式表示难以做到）。

### 阶段D：接触估计（瞬时 & 累计）

- **瞬时接触图**：对手上每个高斯找物体上最近高斯，若中心距 d<τd<\taud<τ 记为接触（物体看手同理）；构成 3D 接触图 $C=\{d(G_h,G_o)\ \text{if }d<\tau;\ 0\ \text{else}\}$。
- **累计接触图**：沿时间把瞬时接触累加，得到抓握过程的“热区”；论文显式支持**瞬时与累计**两类接触输出。

---

## 数据集：MANUS-Grasps

---

- **动机**：为支持神经场/3DGS 的**高视角密度**与强对齐，现有多视角抓握数据要么硬件特殊（热成像/标记/手套）、要么视角少、且接触多靠估计。
- **采集系统**：**53 台 RGB 相机**均布立方体内壁，**120 FPS, 1280×720，软同步误差 ≤3 ms**；COLMAP 标定。
- **规模**：**50+ 相机、30+ 场景、3 名被试、总计约 700 万帧**，覆盖 360° 抓握过程。
- **真值接触**：15 组序列在物体表面涂**亮绿色湿漆**，抓握后漆转移到手上；通过多视图重建与分割得到**物理真实的累计接触真值**（优于热像法的扩散误差）。
- **标注**：提供 2D/3D 关节、手/物体分割掩膜；分割用 **SAM + Instant-NGP** 保证多视图一致。

---

## 贡献/成果

---

- **MANUS-Hand**：基于 3DGS 的**可动手部表示**，兼顾几何/外观与像素级对齐；
- **MANUS（抓握捕捉）**：手与物体统一为高斯原语，**高效**计算**瞬时/累计接触**；
- **MANUS-Grasps**：**50+ 相机、~700 万帧**的大规模多视角抓握数据，含**湿漆真值接触**评测；
- **接触度量与实验**：在实物抓握上**显著优于 MANO/HARP**；并分析了视角数的重要性。

---